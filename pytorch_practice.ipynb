{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzxJlOxgAAxjvTBQD5l/S1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jjieun1212/basic_project/blob/main/pytorch_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# RNN의 하이퍼파라미터 설정\n",
        "n_hidden = 35      # 은닉층 크기\n",
        "lr = 0.01          # 학습률\n",
        "epochs = 1000      # 에폭 수\n",
        "\n",
        "# 학습할 문자열\n",
        "string = \"hello pytorch. how long can a single string be?\"\n",
        "\n",
        "# 사용할 문자 집합 정의\n",
        "chars = \"abcdefghijklmnopqrstuvwxyz ?!.,:;01\"\n",
        "char_list = [c for c in chars]\n",
        "n_letters = len(char_list)  # 전체 문자 개수 (입력/출력 벡터 차원 수)\n",
        "\n",
        "# 문자열을 one-hot 인코딩된 numpy 배열로 변환\n",
        "def string_to_onehot(input_string):\n",
        "    start = np.zeros((0, n_letters), dtype=int)  # 빈 배열 생성 (문자 수 × n_letters 크기로 누적)\n",
        "    for ch in input_string:\n",
        "        zero = np.zeros(n_letters, dtype=int)  # 모든 값 0인 벡터\n",
        "        idx = char_list.index(ch)              # 해당 문자 인덱스 찾기\n",
        "        zero[idx] = 1                           # 해당 위치에 1 설정 (one-hot)\n",
        "        start = np.vstack([start, zero])        # 행 방향으로 쌓기\n",
        "    return start\n",
        "\n",
        "# one-hot 벡터를 문자로 디코딩\n",
        "def onehot_to_word(onehot_1):\n",
        "    onehot = onehot_1.detach().cpu().numpy()  # 텐서를 numpy 배열로 변환\n",
        "    idx = onehot.argmax()                     # 가장 큰 값의 인덱스를 문자 인덱스로\n",
        "    return char_list[idx]                     # 해당 인덱스의 문자 반환\n",
        "\n",
        "# RNN 모델 클래스 정의\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        super(RNN, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "        # 입력 → 은닉층 선형 변환\n",
        "        self.i2h = nn.Linear(input_size, hidden_size)\n",
        "        # 이전 은닉 → 현재 은닉\n",
        "        self.h2h = nn.Linear(hidden_size, hidden_size)\n",
        "        # 은닉 → 출력\n",
        "        self.i2o = nn.Linear(hidden_size, output_size)\n",
        "        # 활성화 함수\n",
        "        self.act_fn = nn.Tanh()\n",
        "\n",
        "    # 순전파 함수 정의\n",
        "    def forward(self, input, hidden):\n",
        "        # 현재 입력과 이전 은닉 상태를 이용해 새로운 은닉 상태 계산\n",
        "        hidden = self.act_fn(self.i2h(input) + self.h2h(hidden))\n",
        "        # 은닉 상태를 출력 벡터로 변환\n",
        "        output = self.i2o(hidden)\n",
        "        return output, hidden\n",
        "\n",
        "    # 은닉 상태 초기화 (0으로 시작)\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(1, self.hidden_size)\n",
        "\n",
        "# 모델 인스턴스 생성\n",
        "rnn = RNN(n_letters, n_hidden, n_letters)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 설정\n",
        "loss_func = nn.MSELoss()\n",
        "optimizer = optim.Adam(rnn.parameters(), lr=lr)\n",
        "\n",
        "# 문자열을 one-hot 텐서로 변환\n",
        "one_hot = torch.from_numpy(string_to_onehot(string)).float()\n",
        "\n",
        "# 모델 학습\n",
        "for epoch in range(epochs):\n",
        "    rnn.zero_grad()                   # 기울기 초기화\n",
        "    total_loss = 0                   # 에폭별 손실 누적 변수\n",
        "    hidden = rnn.init_hidden()       # 은닉 상태 초기화\n",
        "\n",
        "    # 문자열의 각 문자에 대해 다음 문자 예측\n",
        "    for j in range(one_hot.size(0) - 1):\n",
        "        input_ = one_hot[j].unsqueeze(0)      # 입력 벡터 (1 x n_letters)\n",
        "        target = one_hot[j + 1]               # 정답 벡터\n",
        "\n",
        "        output, hidden = rnn(input_, hidden)  # RNN 순전파\n",
        "        loss = loss_func(output.view(-1), target.view(-1))  # 손실 계산\n",
        "        total_loss += loss                    # 손실 누적\n",
        "\n",
        "    total_loss.backward()  # 역전파\n",
        "    optimizer.step()       # 가중치 갱신\n",
        "\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {total_loss.item()}\")\n",
        "\n",
        "# 학습한 모델로 문자열 생성\n",
        "start = torch.zeros(1, n_letters)                   # 시작 입력 벡터\n",
        "start[0, char_list.index(\".\")] = 1                  # '.'에서 시작한다고 가정\n",
        "\n",
        "with torch.no_grad():                               # 추론 단계에서는 기울기 계산 X\n",
        "    hidden = rnn.init_hidden()                      # 은닉 상태 초기화\n",
        "    input_ = start\n",
        "    output_string = \"\"                              # 생성된 문자열 저장용\n",
        "    for i in range(len(string)):                    # 기존 문자열 길이만큼 생성\n",
        "        output, hidden = rnn(input_, hidden)        # 한 글자씩 예측\n",
        "        char = onehot_to_word(output)               # 예측 벡터 → 문자\n",
        "        output_string += char                       # 문자열에 추가\n",
        "        input_ = output                             # 출력 → 다음 입력\n",
        "\n",
        "print(\"Generated string:\")\n",
        "print(output_string)  # 최종 생성된 문자열 출력\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHaK7KAF5E2Q",
        "outputId": "857ec541-962e-458a-f1bf-d7b7d8ad477e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 2.492001533508301\n",
            "Epoch 100, Loss: 0.08108144253492355\n",
            "Epoch 200, Loss: 0.027850287035107613\n",
            "Epoch 300, Loss: 0.014384732581675053\n",
            "Epoch 400, Loss: 0.011849197559058666\n",
            "Epoch 500, Loss: 0.00890377163887024\n",
            "Epoch 600, Loss: 0.004499353002756834\n",
            "Epoch 700, Loss: 0.003697757376357913\n",
            "Epoch 800, Loss: 0.0029422976076602936\n",
            "Epoch 900, Loss: 0.0029318819288164377\n",
            "Generated string:\n",
            "s biatgln tr n tginr e ngin  o tglr ns trbn tra\n"
          ]
        }
      ]
    }
  ]
}